{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'UMAP' from 'umap' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mumap_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UMAP\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HDBSCAN\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/litreview-BYspwzaP-py3.11/lib/python3.11/site-packages/bertopic/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.16.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m ]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/litreview-BYspwzaP-py3.11/lib/python3.11/site-packages/bertopic/_bertopic.py:38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Models\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UMAP\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m sklearn_version\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'UMAP' from 'umap' (unknown location)"
     ]
    }
   ],
   "source": [
    "from umap.umap_ import UMAP\n",
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store processed texts\n",
    "processed_texts = []\n",
    "# arrays for extra info like name, year, etc\n",
    "abstracts = []\n",
    "filtered_dates = []\n",
    "filtered_titles = []\n",
    "\n",
    "# Apply preprocess_text function to each description\n",
    "for i, description in enumerate(descriptions):\n",
    "    if not isinstance(description, (float, int)):\n",
    "        processed = preprocess_text(description)\n",
    "        processed_texts.append(processed)\n",
    "        abstracts.append(description)\n",
    "        if i < len(dates) and i < len(titles):\n",
    "            filtered_dates.append(dates[i])\n",
    "            if not isinstance(titles[i], (float, int)):\n",
    "                filtered_titles.append(titles[i])\n",
    "\n",
    "# Output the lists to verify correct processing\n",
    "print(\"Processed Texts:\", processed_texts)\n",
    "print(\"Abstracts:\", abstracts)\n",
    "print(\"Filtered Dates:\", filtered_dates)\n",
    "print(\"Filtered Titles:\", filtered_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BERTopic instance with desired topic size and automatic number of topics\n",
    "umap_model = UMAP(n_components=5, n_neighbors=15, min_dist=0.0)\n",
    "hdbscan_model = HDBSCAN(min_samples=10, gen_min_span_tree=True, prediction_data=True)\n",
    "\n",
    "# embedding model for higher quality\n",
    "embedding_model = AutoModel.from_pretrained(\"Salesforce/SFR-Embedding-2_R\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    embedding_model=embedding_model,\n",
    "    nr_topics=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the preprocessed texts\n",
    "# topics stores topics assigned to documents\n",
    "topics, probabilities = topic_model.fit_transform(processed_texts)\n",
    "\n",
    "# Reduce outliers\n",
    "new_topics = topic_model.reduce_outliers(processed_texts, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic coordinates\n",
    "fig = topicmodel.visualize_topics()\n",
    "scatter_data = fig.data[0]\n",
    "\n",
    "# Ensure coordinates length matches topics length\n",
    "coordinates_length = min(len(scatter_data[\"x\"]), len(topics))\n",
    "\n",
    "# Get topic embeddings\n",
    "topic_embeddings = topic_model.topic_embeddings\n",
    "\n",
    "# Ensure probs is a 2D array\n",
    "probs = np.array(probabilities)\n",
    "\n",
    "# If probs is a 1D array, reshape it to 2D\n",
    "if probs.ndim == 1:\n",
    "    probs = probs.reshape(-1, 1)\n",
    "\n",
    "# Use UMAP to reduce the dimensionality of the topic distributions\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.3, metric=\"correlation\")\n",
    "umap_embeddings = umap_model.fit_transform(probs)\n",
    "\n",
    "# Create a DataFrame with individual documents and their UMAP embeddings\n",
    "data = []\n",
    "for i in range(len(processed_texts)):\n",
    "    data.append(\n",
    "        {\n",
    "            \"topic\": topics[i],\n",
    "            \"processed_text\": processed_texts[i],\n",
    "            \"abstract\": abstracts[i],\n",
    "            \"title\": titles[i],\n",
    "            \"date\": dates[i],\n",
    "            \"x\": umap_embeddings[i, 0],\n",
    "            \"y\": umap_embeddings[i, 1],\n",
    "        }\n",
    "    )\n",
    "\n",
    "documents_df = pd.DataFrame(data)\n",
    "\n",
    "# Enable JSON data transformer\n",
    "alt.data_transformers.enable(\"json\")\n",
    "\n",
    "# Create Altair chart\n",
    "chart = (\n",
    "    alt.Chart(documents_df)\n",
    "    .mark_circle()\n",
    "    .encode(\n",
    "        x=\"x:Q\",\n",
    "        y=\"y:Q\",\n",
    "        color=\"topic:N\",\n",
    "        tooltip=[\"topic:N\", \"title:N\", \"date:N\", \"abstract:N\"],\n",
    "    )\n",
    "    .interactive()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litreview-BYspwzaP-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
